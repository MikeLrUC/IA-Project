\documentclass[letterpaper,10pt]{article}

\usepackage[width=185mm,top=10mm,bottom=25mm]{geometry}

\usepackage[backend=biber,style=alphabetic,sorting=ynt]{biblatex} 
\addbibresource{references.bib} 

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage[parfill]{parskip}

\usepackage{url}
\usepackage{hyperref}

\hypersetup{
  colorlinks = true,
  linkcolor = blue,
  filecolor = magenta,      
  urlcolor = cyan,
  pdftitle = {Artificial Guide Dogs - Reinforcement Learning Approach for 
  Training Disabled People Personal Companions},
  pdfauthor = {Miguel Rabuge, Gabriel Fernandes, Pedro Rodrigues},
  pdfsubject = {Project Proposal},
  pdfkeywords = {Artificial Intelligence, Machine Learning,
  Reinforcement Learning},
  pdfproducer = {Latex with hyperref},
  pdfcreator = {pdflatex}
}

\title{
  \textbf{Artificial Guide Dogs} \\\vspace{2pt}
  \large{Reinforcement Learning Approach for Training Disabled People 
  Personal Companions} \\\vspace{2pt}
  \Large{Project Proposal} 
} 

\author{
  Miguel Rabuge\\
  University of Coimbra\\
  DEI, Portugal \\
  \texttt{rabuge@student.dei.uc.pt}
  \and
  Gabriel Fernandes\\
  University of Coimbra\\
  DEI, Portugal\\
  \texttt{gabrielf@student.dei.uc.pt}
  \and
  Pedro Rodrigues\\
  University of Coimbra\\
  DEI, Portugal \\
  \texttt{pedror@student.dei.uc.pt}
}

\begin{document}

\maketitle
\tableofcontents

\section{Problem}

Nowadays, there is a lot of effort being put into solving the problem of 
autonomous driving, not only because of research but also because of the 
security and comfort that autonomous vehicle may bring to our lives. Despite 
the fact, this problem being hard, it is made easy because of the environment
where the action of driving happens. There are a set of rules about how 
to drive, and where to drive in order to avoid potential accidents resulting 
in collisions with other vehicles, persons or objects. In other words, the 
environment is dynamic and risky but, it is less chaotic and more well defined 
than others, which becomes more suited for the development artificial of
intelligence approaches for training vehicles to be autonomous.

To our knowledge, there has not been a lot of development of similar
techniques for pedestrians, namely the ones that show some form of 
disability that could put them in danger if not accompanied by some form 
of personal companion. In fact, the pedestrian environment, unlike the
one where vehicles circulate, does not have a set of rules describing the 
way people should walk nor a place where the action of walking takes place.
The pedestrian may be forced to walk in a sidewalk, in a rugged terrain or 
even in the car lane if no sidewalk exists. Additionally, the objects that 
a pedestrian needs to avoid obviously increases since a person needs not to
worry only about walking itself, but also other obstacles with a more
unpredictable moving patterns. Therefore, the environment is often so chaotic 
that traveling by foot requires assistance and makes the problem less 
approachable from an artificial intelligence standpoint.

Since the problem of autonomous mobility for disabled pedestrians is not
particularly developed, and the only way such mobility can be achieved is
with the help of some form of companion, (like for instance a guide dog
which requires a lot of training in order to successfully guide people), 
our idea is to use some form of reinforcement learning technique and train 
a intelligent agent, therefore reducing the time and costs that would be 
required in the acquisition and training of a real personal companion. 

In short with this project we aim to explore techniques to train the agent to 
assess the hardness of the environment and all the obstacles present in order
to determine a suitable footpath and guide in some way the person through it.
In our research, we intent to start with more accessible environments 
progressing to more challenging ones as we go along. We will also focus 
on visually impaired people since they are representative of a group that
could benefit a lot from the development of this technology.

\section{State of The Art / Literature Review}

From our research about the reinforcement learning methodology \cite{sutton}
we intend to apply in the training of our intelligent agent we found that a 
lot of work has been made on this topic both at a theoretical/algorithmic
\cite{MARL:overview,DBLP:journals/corr/abs-1911-10635}
and practical level. There exist many implementations and approaches that 
rely on this method for solving problems that involve complex environments 
where an agent placed in the system must choose the optimal way to interact with 
it in order to obtain the reward that maximizes the objectives that the agent 
is set to solve. For instance, there is a lot of research on the autonomous 
driving problem that use reinforcement learning techniques that we plan 
to build upon in the scope of this project. 

In terms of autonomous driving we found a lot of material that ranges from 
simulators \cite{duckietown-library} that rely on a virtual environment to 
train an agent that will later be put in the same scenario but in real 
life, to strategies using known algorithms \cite{vieira2021openworld} to 
detect and classify entities that may appear as obstacles for a vehicle.
Although these resources provide us with a lot of tools, unfortunately they 
do not fit entirely our goals. As we need not to simulate car lanes and 
other car traffic signals but sidewalks and pedestrian related signals, and 
the majority of obstacles will be most certainly people. However, these 
resources will become a benchmark for the development of our project.

More related with our project proposal we found that some work as already
been made not only in the recognition of pedestrians \cite{dataflair_2021}
but also using drones as footpath finders \cite{tan2021flying}, 
therefore helping the visually impaired people circulation, especially 
through car lanes. These are the most relevant resources that we found on 
this topic and that convey the main idea we want to further explore.

\section{Materials - Datasets, Frameworks and Algorithms} 

In terms of data sets we found a few resources online. The following list
illustrates ones that are going to potentially be used by us during the 
development of this project:
\begin{itemize}
  \item Penn-Fudan Pedestrian Detection and Segmentation: 
    \url{https://www.cis.upenn.edu/~jshi/ped_html/}
  \item Flying Guide Dog: 
    \url{https://drive.google.com/drive/folders/1UFcr-b4Ci5BsA72TZWJ77n-
    J3aneli6l}
  \item Pedestrian Datasets: \url{https://www.cognata.com/pedestrian-datasets/}
  \item UoL Corridor long-term pedestrian dataset: \url{https://lcas.lincoln.
    ac.uk/wp/research/data-sets-software/uol-corridor-long-term-pedestrian-
    dataset/}
\end{itemize}
In terms of frameworks we have a few options that we plan to explore: 
\begin{itemize}
  \item DuckieTown: \url{https://github.com/duckietown} 
  \item Flying-Guide-Dogs: 
    \url{https://github.com/EckoTan0804/flying-guide-dog}
  \item Python + ML/RL Libraries: 
    \url{https://data-flair.training/blogs/pedestrian-detection-python-opencv/}
\end{itemize}
As for algorithms we are still discussing and reading about the topic and we
soon hope to find the ones that will be better for our task.

\section{Design of The Experiments}

The design of the experiments to be carried out will be based on the 
detection of entities, namely people, traffic lights, crossings, 
stairs, etc... . The objective of the agent is to present a behavior 
appropriate to the environment presented to him. The evaluation of this 
behavior will be made by success metrics, to develop, which will serve 
to inform us about the parameters that we must change, in order to obtain 
the expected performance, that is, that can navigate a dynamic environment 
safeguarding the physical integrity of the agent.

In terms of the experimental setup, we thought about how would we implement
experiments to train/test our agent in multiple environments, since its 
really hard to model such complex system using the data available to us. 
One of the alternatives is to provide the agent with 2D images and through 
reinforcement learning the agent would select the regions on that image that 
would provide a viable path avoiding collisions with objects. A more advanced 
and realistic way would be to design 3D virtual environments and test the 
agent on those. Both options at the moment show promise, and perhaps 
there might be even more possibilities to explore.
We are still exploring more on this and we expect to reach 
conclusions anytime soon.

\printbibliography

\end{document}

